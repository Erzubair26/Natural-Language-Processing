{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66f35f6-437f-4d7f-a92f-03aec6af86fc",
   "metadata": {},
   "source": [
    "Stemming and its Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e12fe-65ad-4d6a-9184-efc71c86d77e",
   "metadata": {},
   "source": [
    "What is Stemming?\n",
    "\n",
    "* Stemming refers to the process of reducing a word to its base or root form, which may not correspond to a valid dictionary entry.\n",
    "* Example:\n",
    "  * running → run\n",
    "  * studies → studi\n",
    "* The primary purpose of stemming is to treat morphologically similar words as equivalent during tasks such as information retrieval (IR), search engine indexing, text mining, and sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4010d-380a-4759-baf6-735808783331",
   "metadata": {},
   "source": [
    "Porter Stemmer\n",
    "\n",
    "* The Porter Stemmer is the most widely used rule-based stemming algorithm. It was developed in 1980 by Martin Porter.\n",
    "* This algorithm applies a series of rules to remove common suffixes such as -ing, -ed, and -s from words.\n",
    "* An advantage of the Porter Stemmer is its simplicity and speed, which make it effective for processing English text.\n",
    "* A limitation of the Porter Stemmer is its tendency to over-stem or under-stem certain words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30160a7-3f76-44f6-acd9-e69d9ff51e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02cf442b-208e-44bd-9a7e-580a211597a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44222d9d-19d8-4a62-944e-bf13fae3605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"running\", \"played\", \"cars\", \"happiness\",\"working\",\"eating\",\"eaten\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04770174-f723-4793-a8ff-988bcdb90f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running---->run\n",
      "played---->play\n",
      "cars---->car\n",
      "happiness---->happi\n",
      "working---->work\n",
      "eating---->eat\n",
      "eaten---->eaten\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+P_stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449cb98-3d56-454c-bd68-c64eefa619ec",
   "metadata": {},
   "source": [
    "Snowball Stemmer\n",
    "\n",
    "* The Snowball Stemmer is an improved version of the Porter Stemmer, also developed by Martin Porter.\n",
    "* It supports multiple languages, including English, French, and German.\n",
    "* The Snowball Stemmer is more consistent and aggressive than the original Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f804c3-e6c1-4c3b-801e-b8b0309dd73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e53cfe1-be5d-479f-8608-a498246f95a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running---->run\n",
      "played---->play\n",
      "cars---->car\n",
      "happiness---->happi\n",
      "working---->work\n",
      "eating---->eat\n",
      "eaten---->eaten\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d37276-720f-4a83-8c32-c23c119cd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "R_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6b911b-30e2-424d-9c4b-c475cc2df7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running---->runn\n",
      "played---->played\n",
      "cars---->car\n",
      "happiness---->happines\n",
      "working---->work\n",
      "eating---->eat\n",
      "eaten---->eaten\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+R_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab60b5d-4a01-4bf6-9808-29634aff587f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a463a35-909a-4083-99a8-bfaa8de928ec",
   "metadata": {},
   "source": [
    "Regular Expression Stemmer (RegexpStemmer)\n",
    "\n",
    "The Regular Expression Stemmer removes word endings using user-defined regular expression patterns.\n",
    "\n",
    "Users can specify custom suffix patterns to tailor the stemming process.\n",
    "\n",
    "Advantage: The approach is fully customizable.\n",
    "\n",
    "Disadvantage: This method can be crude and may not generalize effectively across different word forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a24b6-4136-408c-9bd2-5f663d25a0e1",
   "metadata": {},
   "source": [
    "Lancaster Stemmer\n",
    "\n",
    "* The Lancaster Stemmer is highly aggressive and often removes substantial portions of words, which can result in excessive truncation.\n",
    "* This algorithm may generate stems that do not resemble the original words, potentially reducing interpretability.\n",
    "* Advantage: The Lancaster Stemmer is very fast.\n",
    "* Disadvantage: It often results in over-stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87db7337-5e57-4c49-aa9f-311f92291835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "L_stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9db0d3b1-e609-4543-a05b-849d03dc7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running---->run\n",
      "played---->play\n",
      "cars---->car\n",
      "happiness---->happy\n",
      "working---->work\n",
      "eating---->eat\n",
      "eaten---->eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+L_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afc252-69f1-45a0-ad38-269138913118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
